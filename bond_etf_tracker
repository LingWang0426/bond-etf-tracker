# bond_etf_tracker.py
import streamlit as st
import pandas as pd
import yfinance as yf
import datetime
import requests
from bs4 import BeautifulSoup

# --------------------- CONFIG ---------------------
target_allocations = {
    "VGOV": 21000,
    "IEF": 18000,
    "TLT": 12000,
    "AGGH": 9000
}
total_investment = sum(target_allocations.values())

# --------------------- PAGE SETUP ---------------------
st.set_page_config(page_title="债券ETF建仓追踪器", layout="wide")
st.title("📊 债券ETF建仓追踪器")

# --------------------- PRICE FETCHING ---------------------
def get_price(ticker):
    try:
        data = yf.Ticker(ticker).history(period="1d")
        return round(data['Close'].iloc[-1], 2)
    except:
        return "N/A"

etf_prices = {
    "VGOV": get_price("VGOV.L"),
    "IEF": get_price("IEF"),
    "TLT": get_price("TLT"),
    "AGGH": get_price("AGGH.L")
}

# --------------------- INPUT TRACKER ---------------------
st.subheader("✅ 当前持仓记录（手动输入或连接账户）")
input_data = []

for etf, target in target_allocations.items():
    col1, col2, col3 = st.columns([2, 2, 2])
    with col1:
        bought = st.number_input(f"{etf} 已买入金额 (£)", min_value=0, max_value=int(target), value=0, step=100)
    with col2:
        st.markdown(f"**当前价格：** {etf_prices[etf]} $")
    with col3:
        pct = (bought / target) * 100 if target > 0 else 0
        st.markdown(f"**建仓进度：** {pct:.1f}%")
    input_data.append((etf, bought, target, pct))

# --------------------- PROGRESS TABLE ---------------------
st.subheader("📋 建仓进度汇总")
df = pd.DataFrame(input_data, columns=["ETF", "已买入 (£)", "目标金额 (£)", "进度 (%)"])
st.dataframe(df.set_index("ETF"))

# --------------------- 新闻抓取功能 ---------------------
st.subheader("📰 最新央行降息信号追踪")

@st.cache_data(ttl=3600)
def fetch_interest_news(country):
    query = f"{country} central bank interest rate cut site:reuters.com OR site:bbc.com OR site:bloomberg.com"
    url = f"https://www.bing.com/search?q={query}"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    soup = BeautifulSoup(resp.text, "html.parser")
    results = []
    for li in soup.find_all("li"):
        a = li.find("a")
        if a and a.get("href") and a.text:
            results.append((a.text.strip(), a.get("href")))
        if len(results) >= 5:
            break
    return results

with st.expander("🇬🇧 英国央行降息相关新闻"):
    for title, link in fetch_interest_news("UK"):
        st.markdown(f"- [{title}]({link})")

with st.expander("🇺🇸 美国联储降息相关新闻"):
    for title, link in fetch_interest_news("US"):
        st.markdown(f"- [{title}]({link})")

# --------------------- END ---------------------
st.markdown("---")
st.caption("如需提醒功能，可结合 email + GitHub Actions 定时运行此页面逻辑。")
